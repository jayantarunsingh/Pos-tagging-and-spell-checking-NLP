# -*- coding: utf-8 -*-
"""final_project(nlp).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YD9rvqAfIxCML4YzS-9q1oog96IF7ASe
"""

!pip install stanza indic-nlp-library

import stanza
import pandas as pd
from indicnlp.tokenize import indic_tokenize
import matplotlib.pyplot as plt
import seaborn as sns

# Download Telugu model for Stanza (if not already downloaded)
stanza.download('te', processors='tokenize,pos')

# Initialize the Telugu NLP pipeline
nlp = stanza.Pipeline('te', processors='tokenize,pos', use_gpu=False)

# Load the dataset
file_path = '/content/dataset(nlp).csv'
df = pd.read_csv(file_path)

# Fill missing data if any
df['Verse'] = df['Verse'].fillna('')

# Get the number of rows
print(df.shape[0])

df.head()

# Tokenization and POS tagging using Stanza
def stanza_pos_tagging(verse):
    doc = nlp(verse)
    tokens_and_tags = [(word.text, word.pos) for sentence in doc.sentences for word in sentence.words]
    return tokens_and_tags

# Apply POS tagging to each verse
df['POS_Tags'] = df['Verse'].apply(stanza_pos_tagging)

# Convert the DataFrame into a format with one word per row and corresponding POS tag
formatted_data = []
for _, row in df.iterrows():
    for word, pos in row['POS_Tags']:
        formatted_data.append({'Word': word, 'POS_Tag': pos})

# Create a new DataFrame for the formatted data
formatted_df = pd.DataFrame(formatted_data)

plt.figure(figsize=(10, 6))
pos_counts = formatted_df['POS_Tag'].value_counts()
sns.barplot(x=pos_counts.index, y=pos_counts.values, palette='Blues_d')
plt.title('POS Tag Distribution')
plt.ylabel('Count')
plt.xlabel('POS Tag')
plt.xticks(rotation=45)
plt.show()

# Adding a column for Spell Checking (this is a placeholder function for now)
# You can replace this with a real spell-checking function using Indic NLP or any other method
def spell_check(word):
    # A very basic spell check (replace with a real spell checker or a word list)
    if len(word) > 0:  # Example condition, can be any spell check logic
        return "Correct"
    else:
        return "Incorrect"

# Example usage
word = 'వ్రాయబడిం'
result = spell_check(word)
print(f"The word '{word}' is {result}.")

# # Apply spell checking
formatted_df['Spell_Check'] = formatted_df['Word'].apply(spell_check)

# Save the formatted data to a CSV file
output_file_path = 'path_to_save_output.csv'
formatted_df.to_csv(output_file_path, index=False)

print(f"Formatted dataset saved to {output_file_path}")

# Print out the first few rows of the DataFrame to verify

formatted_df.columns
formatted_df.head(20)

import pandas as pd
import difflib

# Load the dataset from the CSV file
file_path = 'path_to_save_output.csv'  # Update this with the actual file path in your colab
df = pd.read_csv(file_path)

# Display the first few rows
df.head()

# Group by sentences (use punctuation to split sentences)
def group_sentences(df):
    sentences = []
    current_sentence = []
    for idx, row in df.iterrows():
        current_sentence.append((row['Word'], row['POS_Tag'], row['Spell_Check']))
        if row['Word'] in ['.', '!', '?']:  # End of sentence
            sentences.append(current_sentence)
            current_sentence = []
    if current_sentence:  # Append any remaining sentence
        sentences.append(current_sentence)
    return sentences

# Get sentence-wise data
sentences = group_sentences(df)

# Display the structure of one sentence for reference
for sentence in sentences[:1]:  # Show first sentence
    print(sentence)

# Function to correct misspelled words in each sentence
def spellcheck_sentence(sentence, correct_words):
    corrected_sentence = []
    for word, pos, spell in sentence:
        # Apply correction only if the word is incorrect
        if spell == 'Incorrect':
            corrected_word = difflib.get_close_matches(word, correct_words, n=1)
            corrected_word = corrected_word[0] if corrected_word else word
        else:
            corrected_word = word
        corrected_sentence.append((corrected_word, pos))
    return corrected_sentence

# List of correct words from the dataset
correct_words = df[df['Spell_Check'] == 'Correct']['Word'].unique().tolist()

# Apply spellcheck to each sentence
corrected_sentences = [spellcheck_sentence(sentence, correct_words) for sentence in sentences]

# Placeholder for a function to tag POS for corrected sentences
# Assuming you have a trained POS model or using a simple tagger (replace with actual model if needed)
def pos_tag_sentence(corrected_sentence):
    # Dummy POS tagging logic (replace with actual model predictions)
    return [(word, pos) for word, pos in corrected_sentence]

# Apply POS tagging to each corrected sentence
pos_tagged_sentences = [pos_tag_sentence(sentence) for sentence in corrected_sentences]

# Function to print sentence-wise results
def display_results(original_sentences, corrected_sentences, pos_tagged_sentences):
    for i, sentence in enumerate(original_sentences[:5]):  # Display first 5 sentences
        original_sentence = " ".join([w[0] for w in sentence if w[0] not in ['.', '!', '?']]) + sentence[-1][0]
        corrected_sentence = " ".join([w[0] for w in corrected_sentences[i] if w[0] not in ['.', '!', '?']]) + corrected_sentences[i][-1][0]
        pos_tagged_output = [(w[0], w[1]) for w in pos_tagged_sentences[i] if w[0] not in ['.', '!', '?']]

        print(f"Original Verse {i+1}: {original_sentence}")
        print(f"Spellchecked Output {i+1}: {corrected_sentence}")
        print(f"POS Tagged Output {i+1}: {pos_tagged_output}\n")

# Display results for the first 5 sentences
display_results(sentences, corrected_sentences, pos_tagged_sentences)

